\Ac{DL}, a family of data-driven artificial intelligence techniques, has
shown immense promise in a plethora of applications, and it has even outpaced 
experts in several domains. However, unlike symbolic approaches to learning,
these methods fall short when it comes to abiding by and learning from 
pre-existing established principles. This is a significant deficit for 
deployment in critical applications such as robotics, medicine, industrial
automation, etc. For a decision system to be considered for adoption in such
fields, it must demonstrate the ability to adhere to specified constraints, 
an ability missing in \ac{DL}-based approaches. Exploring this problem
serves as the core tenet of the dissertation.

The dissertation starts with an exploration of the abilities of conventional
\ac{DL}-based systems \emph{vis-\`a-vis} domain coherence. A large-scale
rule-annotated dataset is introduced to mitigate the pronounced lack of suitable
constraint adherence evaluation benchmarks, and with its aid, the rule adherence
abilities of vision systems are analyzed. Additionally, this study probes
language models to elicit their performance characteristics with regard to
domain consistency. Examination of these language models with interventions
illustrates their ineptitude at obeying domain principles, and a mitigation
strategy is proposed. This is followed by an exploration of techniques for
imbuing deep learning systems with domain constraint information. Also, a
comprehensive study of standard evaluation metrics and their blind spots
pertaining to domain-aware performance estimation is undertaken. Finally, a
novel technique to enforce constraint compliance in models without training is
introduced, which pairs a search strategy with large language models to achieve
cutting-edge performance.
